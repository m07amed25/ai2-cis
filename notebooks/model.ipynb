{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e9bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor, StackingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45a279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\AI\\ai2-project\\data\\1553768847-housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfc61ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.2300</td>\n",
       "      <td>37.8800</td>\n",
       "      <td>41</td>\n",
       "      <td>880</td>\n",
       "      <td>129.0000</td>\n",
       "      <td>322</td>\n",
       "      <td>126</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>452600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.2200</td>\n",
       "      <td>37.8600</td>\n",
       "      <td>21</td>\n",
       "      <td>7099</td>\n",
       "      <td>1106.0000</td>\n",
       "      <td>2401</td>\n",
       "      <td>1138</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>358500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.2400</td>\n",
       "      <td>37.8500</td>\n",
       "      <td>52</td>\n",
       "      <td>1467</td>\n",
       "      <td>190.0000</td>\n",
       "      <td>496</td>\n",
       "      <td>177</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>352100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.2500</td>\n",
       "      <td>37.8500</td>\n",
       "      <td>52</td>\n",
       "      <td>1274</td>\n",
       "      <td>235.0000</td>\n",
       "      <td>558</td>\n",
       "      <td>219</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>341300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.2500</td>\n",
       "      <td>37.8500</td>\n",
       "      <td>52</td>\n",
       "      <td>1627</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>565</td>\n",
       "      <td>259</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>342200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0  -122.2300   37.8800                  41          880        129.0000   \n",
       "1  -122.2200   37.8600                  21         7099       1106.0000   \n",
       "2  -122.2400   37.8500                  52         1467        190.0000   \n",
       "3  -122.2500   37.8500                  52         1274        235.0000   \n",
       "4  -122.2500   37.8500                  52         1627        280.0000   \n",
       "\n",
       "   population  households  median_income ocean_proximity  median_house_value  \n",
       "0         322         126         8.3252        NEAR BAY              452600  \n",
       "1        2401        1138         8.3014        NEAR BAY              358500  \n",
       "2         496         177         7.2574        NEAR BAY              352100  \n",
       "3         558         219         5.6431        NEAR BAY              341300  \n",
       "4         565         259         3.8462        NEAR BAY              342200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e666aa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08907120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.0000\n",
       "mean    206855.8169\n",
       "std     115395.6159\n",
       "min      14999.0000\n",
       "25%     119600.0000\n",
       "50%     179700.0000\n",
       "75%     264725.0000\n",
       "max     500001.0000\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['median_house_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e11c9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "ocean_proximity         0\n",
       "median_house_value      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd4d5fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (20640, 30)\n",
      "\n",
      "New features created:\n",
      "['rooms_per_household', 'bedrooms_per_room', 'population_per_household', 'bedrooms_per_household', 'income_squared', 'income_cubed', 'income_rooms_interaction', 'income_age_interaction', 'is_new', 'is_old', 'age_squared', 'people_per_room', 'rooms_density', 'lat_lon_interaction', 'distance_to_center', 'distance_to_coast', 'log_population', 'log_total_rooms', 'log_total_bedrooms', 'log_households']\n"
     ]
    }
   ],
   "source": [
    "df_model = df.copy()\n",
    "\n",
    "# Ratio Features\n",
    "df_model['rooms_per_household'] = df_model['total_rooms'] / df_model['households']\n",
    "df_model['bedrooms_per_room'] = df_model['total_bedrooms'] / df_model['total_rooms']\n",
    "df_model['population_per_household'] = df_model['population'] / df_model['households']\n",
    "df_model['bedrooms_per_household'] = df_model['total_bedrooms'] / df_model['households']\n",
    "\n",
    "# Income-based features\n",
    "df_model['income_squared'] = df_model['median_income'] ** 2\n",
    "df_model['income_cubed'] = df_model['median_income'] ** 3\n",
    "df_model['income_rooms_interaction'] = df_model['median_income'] * df_model['rooms_per_household']\n",
    "df_model['income_age_interaction'] = df_model['median_income'] * df_model['housing_median_age']\n",
    "\n",
    "# Age-based features\n",
    "df_model['is_new'] = (df_model['housing_median_age'] < 10).astype(int)\n",
    "df_model['is_old'] = (df_model['housing_median_age'] > 40).astype(int)\n",
    "df_model['age_squared'] = df_model['housing_median_age'] ** 2\n",
    "\n",
    "# Density features\n",
    "df_model['people_per_room'] = df_model['population'] / df_model['total_rooms']\n",
    "df_model['rooms_density'] = df_model['total_rooms'] / df_model['households']\n",
    "\n",
    "# Geographical features\n",
    "df_model['lat_lon_interaction'] = df_model['latitude'] * df_model['longitude']\n",
    "df_model['distance_to_center'] = np.sqrt((df_model['latitude'] - 34.0)**2 + (df_model['longitude'] + 118.0)**2)\n",
    "df_model['distance_to_coast'] = np.abs(df_model['longitude'] + 120.0)\n",
    "\n",
    "# Log transformations for skewed features\n",
    "df_model['log_population'] = np.log1p(df_model['population'])\n",
    "df_model['log_total_rooms'] = np.log1p(df_model['total_rooms'])\n",
    "df_model['log_total_bedrooms'] = np.log1p(df_model['total_bedrooms'])\n",
    "df_model['log_households'] = np.log1p(df_model['households'])\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "df_model.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(f\"shape: {df_model.shape}\")\n",
    "print(f\"\\nNew features created:\")\n",
    "new_features = ['rooms_per_household', 'bedrooms_per_room', 'population_per_household', \n",
    "                'bedrooms_per_household', 'income_squared', 'income_cubed', 'income_rooms_interaction',\n",
    "                'income_age_interaction', 'is_new', 'is_old', 'age_squared', 'people_per_room', \n",
    "                'rooms_density', 'lat_lon_interaction', 'distance_to_center', 'distance_to_coast',\n",
    "                'log_population', 'log_total_rooms', 'log_total_bedrooms', 'log_households']\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72df7a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>bedrooms_per_room</th>\n",
       "      <th>population_per_household</th>\n",
       "      <th>bedrooms_per_household</th>\n",
       "      <th>income_squared</th>\n",
       "      <th>income_cubed</th>\n",
       "      <th>income_rooms_interaction</th>\n",
       "      <th>income_age_interaction</th>\n",
       "      <th>is_new</th>\n",
       "      <th>is_old</th>\n",
       "      <th>age_squared</th>\n",
       "      <th>people_per_room</th>\n",
       "      <th>rooms_density</th>\n",
       "      <th>lat_lon_interaction</th>\n",
       "      <th>distance_to_center</th>\n",
       "      <th>distance_to_coast</th>\n",
       "      <th>log_population</th>\n",
       "      <th>log_total_rooms</th>\n",
       "      <th>log_total_bedrooms</th>\n",
       "      <th>log_households</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.2300</td>\n",
       "      <td>37.8800</td>\n",
       "      <td>41</td>\n",
       "      <td>880</td>\n",
       "      <td>129.0000</td>\n",
       "      <td>322</td>\n",
       "      <td>126</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>452600</td>\n",
       "      <td>6.9841</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>2.5556</td>\n",
       "      <td>1.0238</td>\n",
       "      <td>69.3090</td>\n",
       "      <td>577.0109</td>\n",
       "      <td>58.1443</td>\n",
       "      <td>341.3332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1681</td>\n",
       "      <td>0.3659</td>\n",
       "      <td>6.9841</td>\n",
       "      <td>-4630.0724</td>\n",
       "      <td>5.7400</td>\n",
       "      <td>2.2300</td>\n",
       "      <td>5.7777</td>\n",
       "      <td>6.7811</td>\n",
       "      <td>4.8675</td>\n",
       "      <td>4.8442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.2200</td>\n",
       "      <td>37.8600</td>\n",
       "      <td>21</td>\n",
       "      <td>7099</td>\n",
       "      <td>1106.0000</td>\n",
       "      <td>2401</td>\n",
       "      <td>1138</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>358500</td>\n",
       "      <td>6.2381</td>\n",
       "      <td>0.1558</td>\n",
       "      <td>2.1098</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>68.9132</td>\n",
       "      <td>572.0764</td>\n",
       "      <td>51.7853</td>\n",
       "      <td>174.3294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>441</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>6.2381</td>\n",
       "      <td>-4627.2492</td>\n",
       "      <td>5.7191</td>\n",
       "      <td>2.2200</td>\n",
       "      <td>7.7841</td>\n",
       "      <td>8.8679</td>\n",
       "      <td>7.0094</td>\n",
       "      <td>7.0379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.2400</td>\n",
       "      <td>37.8500</td>\n",
       "      <td>52</td>\n",
       "      <td>1467</td>\n",
       "      <td>190.0000</td>\n",
       "      <td>496</td>\n",
       "      <td>177</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>352100</td>\n",
       "      <td>8.2881</td>\n",
       "      <td>0.1295</td>\n",
       "      <td>2.8023</td>\n",
       "      <td>1.0734</td>\n",
       "      <td>52.6699</td>\n",
       "      <td>382.2462</td>\n",
       "      <td>60.1503</td>\n",
       "      <td>377.3848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2704</td>\n",
       "      <td>0.3381</td>\n",
       "      <td>8.2881</td>\n",
       "      <td>-4626.7840</td>\n",
       "      <td>5.7271</td>\n",
       "      <td>2.2400</td>\n",
       "      <td>6.2086</td>\n",
       "      <td>7.2917</td>\n",
       "      <td>5.2523</td>\n",
       "      <td>5.1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.2500</td>\n",
       "      <td>37.8500</td>\n",
       "      <td>52</td>\n",
       "      <td>1274</td>\n",
       "      <td>235.0000</td>\n",
       "      <td>558</td>\n",
       "      <td>219</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>341300</td>\n",
       "      <td>5.8174</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>2.5479</td>\n",
       "      <td>1.0731</td>\n",
       "      <td>31.8446</td>\n",
       "      <td>179.7021</td>\n",
       "      <td>32.8279</td>\n",
       "      <td>293.4412</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2704</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>5.8174</td>\n",
       "      <td>-4627.1625</td>\n",
       "      <td>5.7345</td>\n",
       "      <td>2.2500</td>\n",
       "      <td>6.3261</td>\n",
       "      <td>7.1507</td>\n",
       "      <td>5.4638</td>\n",
       "      <td>5.3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.2500</td>\n",
       "      <td>37.8500</td>\n",
       "      <td>52</td>\n",
       "      <td>1627</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>565</td>\n",
       "      <td>259</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>342200</td>\n",
       "      <td>6.2819</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>2.1815</td>\n",
       "      <td>1.0811</td>\n",
       "      <td>14.7933</td>\n",
       "      <td>56.8978</td>\n",
       "      <td>24.1613</td>\n",
       "      <td>200.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2704</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>6.2819</td>\n",
       "      <td>-4627.1625</td>\n",
       "      <td>5.7345</td>\n",
       "      <td>2.2500</td>\n",
       "      <td>6.3386</td>\n",
       "      <td>7.3951</td>\n",
       "      <td>5.6384</td>\n",
       "      <td>5.5607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0  -122.2300   37.8800                  41          880        129.0000   \n",
       "1  -122.2200   37.8600                  21         7099       1106.0000   \n",
       "2  -122.2400   37.8500                  52         1467        190.0000   \n",
       "3  -122.2500   37.8500                  52         1274        235.0000   \n",
       "4  -122.2500   37.8500                  52         1627        280.0000   \n",
       "\n",
       "   population  households  median_income ocean_proximity  median_house_value  \\\n",
       "0         322         126         8.3252        NEAR BAY              452600   \n",
       "1        2401        1138         8.3014        NEAR BAY              358500   \n",
       "2         496         177         7.2574        NEAR BAY              352100   \n",
       "3         558         219         5.6431        NEAR BAY              341300   \n",
       "4         565         259         3.8462        NEAR BAY              342200   \n",
       "\n",
       "   rooms_per_household  bedrooms_per_room  population_per_household  \\\n",
       "0               6.9841             0.1466                    2.5556   \n",
       "1               6.2381             0.1558                    2.1098   \n",
       "2               8.2881             0.1295                    2.8023   \n",
       "3               5.8174             0.1845                    2.5479   \n",
       "4               6.2819             0.1721                    2.1815   \n",
       "\n",
       "   bedrooms_per_household  income_squared  income_cubed  \\\n",
       "0                  1.0238         69.3090      577.0109   \n",
       "1                  0.9719         68.9132      572.0764   \n",
       "2                  1.0734         52.6699      382.2462   \n",
       "3                  1.0731         31.8446      179.7021   \n",
       "4                  1.0811         14.7933       56.8978   \n",
       "\n",
       "   income_rooms_interaction  income_age_interaction  is_new  is_old  \\\n",
       "0                   58.1443                341.3332       0       1   \n",
       "1                   51.7853                174.3294       0       0   \n",
       "2                   60.1503                377.3848       0       1   \n",
       "3                   32.8279                293.4412       0       1   \n",
       "4                   24.1613                200.0024       0       1   \n",
       "\n",
       "   age_squared  people_per_room  rooms_density  lat_lon_interaction  \\\n",
       "0         1681           0.3659         6.9841           -4630.0724   \n",
       "1          441           0.3382         6.2381           -4627.2492   \n",
       "2         2704           0.3381         8.2881           -4626.7840   \n",
       "3         2704           0.4380         5.8174           -4627.1625   \n",
       "4         2704           0.3473         6.2819           -4627.1625   \n",
       "\n",
       "   distance_to_center  distance_to_coast  log_population  log_total_rooms  \\\n",
       "0              5.7400             2.2300          5.7777           6.7811   \n",
       "1              5.7191             2.2200          7.7841           8.8679   \n",
       "2              5.7271             2.2400          6.2086           7.2917   \n",
       "3              5.7345             2.2500          6.3261           7.1507   \n",
       "4              5.7345             2.2500          6.3386           7.3951   \n",
       "\n",
       "   log_total_bedrooms  log_households  \n",
       "0              4.8675          4.8442  \n",
       "1              7.0094          7.0379  \n",
       "2              5.2523          5.1818  \n",
       "3              5.4638          5.3936  \n",
       "4              5.6384          5.5607  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82f5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 outliers (0.00%)\n",
      "New dataset shape: (20640, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((16512, 33), (4128, 33))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical variable - One-Hot Encoding\n",
    "df_model = pd.get_dummies(df_model, columns=['ocean_proximity'], drop_first=False)\n",
    "\n",
    "X = df_model.drop('median_house_value', axis=1)\n",
    "y = df_model['median_house_value']\n",
    "\n",
    "Q1 = y.quantile(0.25)\n",
    "Q3 = y.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 3 * IQR\n",
    "upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "outlier_mask = (y >= lower_bound) & (y <= upper_bound)\n",
    "X = X[outlier_mask]\n",
    "y = y[outlier_mask]\n",
    "\n",
    "print(f\"Removed {(~outlier_mask).sum()} outliers ({(~outlier_mask).sum() / len(outlier_mask) * 100:.2f}%)\")\n",
    "print(f\"New dataset shape: {X.shape}\")\n",
    "\n",
    "# missing\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 25 features:\n",
      "['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'population', 'households', 'median_income', 'rooms_per_household', 'bedrooms_per_room', 'population_per_household', 'bedrooms_per_household', 'income_squared', 'income_cubed', 'income_rooms_interaction', 'income_age_interaction', 'age_squared', 'people_per_room', 'rooms_density', 'lat_lon_interaction', 'distance_to_center', 'distance_to_coast', 'log_total_rooms', 'log_households', 'ocean_proximity_<1H OCEAN', 'ocean_proximity_INLAND']\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "# top 25\n",
    "selector = SelectKBest(score_func=mutual_info_regression, k=min(25, X_train.shape[1]))\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "selected_features = X_train.columns[selector.get_support()].tolist()\n",
    "print(f\"Selected {len(selected_features)} features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9771a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial features shape: (16512, 350)\n",
      "Original features: 25, With polynomial: 350\n"
     ]
    }
   ],
   "source": [
    "# polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_selected)\n",
    "X_test_poly = poly.transform(X_test_selected)\n",
    "\n",
    "print(f\"Polynomial features shape: {X_train_poly.shape}\")\n",
    "print(f\"Original features: {X_train_selected.shape[1]}, With polynomial: {X_train_poly.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec4bd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d278e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    cv_rmse = -cv_scores.mean()\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Test MAE': test_mae,\n",
    "        'Train R²': train_r2,\n",
    "        'Test R²': test_r2,\n",
    "        'CV RMSE': cv_rmse,\n",
    "        'Model Object': model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5462a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11 models initialized!\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "results = []\n",
    "\n",
    "# Linear\n",
    "models['Linear Regression'] = LinearRegression()\n",
    "models['Ridge'] = Ridge(alpha=10.0, random_state=42)\n",
    "models['Lasso'] = Lasso(alpha=10.0, random_state=42)\n",
    "models['ElasticNet'] = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)\n",
    "\n",
    "# Tree-based\n",
    "models['Decision Tree'] = DecisionTreeRegressor(max_depth=15, random_state=42)\n",
    "models['Random Forest'] = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Gradient Boosting\n",
    "models['Gradient Boosting'] = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "models['XGBoost'] = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, n_jobs=-1)\n",
    "models['LightGBM'] = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, n_jobs=-1, verbose=-1)\n",
    "models['CatBoost'] = CatBoostRegressor(n_estimators=100, learning_rate=0.1, depth=5, random_state=42, verbose=0)\n",
    "\n",
    "models['AdaBoost'] = AdaBoostRegressor(n_estimators=100, learning_rate=0.5, random_state=42)\n",
    "\n",
    "print(f\"\\n{len(models)} models initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7de8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "\tTest RMSE: $3,574,715.01 | Test R²: -974.1602\n",
      "Training Ridge...\n",
      "\tTest RMSE: $103,035.62 | Test R²: 0.1898\n",
      "Training Lasso...\n",
      "\tTest RMSE: $65,118.51 | Test R²: 0.6764\n",
      "Training ElasticNet...\n",
      "\tTest RMSE: $67,968.18 | Test R²: 0.6475\n",
      "Training Decision Tree...\n",
      "\tTest RMSE: $67,120.55 | Test R²: 0.6562\n",
      "Training Random Forest...\n",
      "\tTest RMSE: $49,370.21 | Test R²: 0.8140\n",
      "Training Gradient Boosting...\n",
      "\tTest RMSE: $46,901.67 | Test R²: 0.8321\n",
      "Training XGBoost...\n",
      "\tTest RMSE: $46,877.63 | Test R²: 0.8323\n",
      "Training LightGBM...\n",
      "\tTest RMSE: $46,849.84 | Test R²: 0.8325\n",
      "Training CatBoost...\n",
      "\tTest RMSE: $51,788.70 | Test R²: 0.7953\n",
      "Training AdaBoost...\n",
      "\tTest RMSE: $79,873.44 | Test R²: 0.5131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train R²</th>\n",
       "      <th>Test R²</th>\n",
       "      <th>CV RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>39148.7600</td>\n",
       "      <td>46849.8400</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>47454.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>37825.0800</td>\n",
       "      <td>46877.6300</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>47611.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>36942.0000</td>\n",
       "      <td>46901.6700</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>47603.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>19234.0100</td>\n",
       "      <td>49370.2100</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>49931.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>48863.4300</td>\n",
       "      <td>51788.7000</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>50914.4600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>58340.0700</td>\n",
       "      <td>65118.5100</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>215805.1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>24003.2100</td>\n",
       "      <td>67120.5500</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>68521.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>63514.0700</td>\n",
       "      <td>67968.1800</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>118391.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>79513.1700</td>\n",
       "      <td>79873.4400</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>78175.5700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>57210.9300</td>\n",
       "      <td>103035.6200</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>3786619.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>53664.8800</td>\n",
       "      <td>3574715.0100</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>-974.1600</td>\n",
       "      <td>6429825.6300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Train RMSE    Test RMSE  Train R²   Test R²  \\\n",
       "8            LightGBM  39148.7600   46849.8400    0.8900    0.8300   \n",
       "7             XGBoost  37825.0800   46877.6300    0.8900    0.8300   \n",
       "6   Gradient Boosting  36942.0000   46901.6700    0.9000    0.8300   \n",
       "5       Random Forest  19234.0100   49370.2100    0.9700    0.8100   \n",
       "9            CatBoost  48863.4300   51788.7000    0.8200    0.8000   \n",
       "2               Lasso  58340.0700   65118.5100    0.7500    0.6800   \n",
       "4       Decision Tree  24003.2100   67120.5500    0.9600    0.6600   \n",
       "3          ElasticNet  63514.0700   67968.1800    0.7000    0.6500   \n",
       "10           AdaBoost  79513.1700   79873.4400    0.5300    0.5100   \n",
       "1               Ridge  57210.9300  103035.6200    0.7600    0.1900   \n",
       "0   Linear Regression  53664.8800 3574715.0100    0.7800 -974.1600   \n",
       "\n",
       "        CV RMSE  \n",
       "8    47454.9300  \n",
       "7    47611.9600  \n",
       "6    47603.9000  \n",
       "5    49931.4800  \n",
       "9    50914.4600  \n",
       "2   215805.1900  \n",
       "4    68521.9300  \n",
       "3   118391.5500  \n",
       "10   78175.5700  \n",
       "1  3786619.8600  \n",
       "0  6429825.6300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    result = evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test, name)\n",
    "    results.append(result)\n",
    "    print(f\"\\tTest RMSE: ${result['Test RMSE']:,.2f} | Test R²: {result['Test R²']:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test MSE')\n",
    "display(results_df[['Model', 'Train RMSE', 'Test RMSE', 'Train R²', 'Test R²', 'CV RMSE']].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d6fa2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_models = {}\n",
    "tuned_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07e08b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF params: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.3, 'max_depth': None}\n",
      "Best RF CV score: $50,926.65\n"
     ]
    }
   ],
   "source": [
    "# Tune Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [25, 30, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['sqrt', 0.3]\n",
    "}\n",
    "\n",
    "rf_grid = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    rf_params,\n",
    "    n_iter=10,\n",
    "    cv=2,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "print(f\"Best RF params: {rf_grid.best_params_}\")\n",
    "print(f\"Best RF CV score: ${-rf_grid.best_score_:,.2f}\")\n",
    "\n",
    "result_rf = evaluate_model(best_rf, X_train_scaled, X_test_scaled, y_train, y_test, 'Random Forest (Tuned)')\n",
    "\n",
    "tuned_results.append(result_rf)\n",
    "tuned_models['Random Forest (Tuned)'] = best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a82455f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB params: {'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 3, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "Best XGB CV score: $46,382.07\n"
     ]
    }
   ],
   "source": [
    "# Tune XGBoost\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train_xgb, X_val_xgb, y_train_xgb, y_val_xgb = tts(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [300, 500],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "xgb_grid = RandomizedSearchCV(\n",
    "    xgb.XGBRegressor(random_state=42, n_jobs=-1, early_stopping_rounds=20),\n",
    "    xgb_params,\n",
    "    n_iter=10,\n",
    "    cv=2,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train_scaled, y_train, \n",
    "             eval_set=[(X_val_xgb, y_val_xgb)],\n",
    "             verbose=False)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "best_xgb.set_params(early_stopping_rounds=None)\n",
    "\n",
    "print(f\"Best XGB params: {xgb_grid.best_params_}\")\n",
    "print(f\"Best XGB CV score: ${-xgb_grid.best_score_:,.2f}\")\n",
    "\n",
    "result_xgb = evaluate_model(best_xgb, X_train_scaled, X_test_scaled, y_train, y_test, 'XGBoost (Tuned)')\n",
    "\n",
    "tuned_results.append(result_xgb)\n",
    "tuned_models['XGBoost (Tuned)'] = best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4e3de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 6.5456e+08\n",
      "Best LGB params: {'subsample': 0.8, 'num_leaves': 31, 'n_estimators': 500, 'max_depth': -1, 'learning_rate': 0.05, 'colsample_bytree': 1.0}\n",
      "Best LGB CV score: $46,064.89\n"
     ]
    }
   ],
   "source": [
    "# Tune LightGBM with early stopping\n",
    "lgb_params = {\n",
    "    'n_estimators': [300, 500],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [7, -1],\n",
    "    'num_leaves': [31, 50],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "lgb_grid = RandomizedSearchCV(\n",
    "    lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
    "    lgb_params,\n",
    "    n_iter=10,\n",
    "    cv=2,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "lgb_grid.fit(X_train_scaled, y_train,\n",
    "             eval_set=[(X_val_xgb, y_val_xgb)],\n",
    "             callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)])\n",
    "best_lgb = lgb_grid.best_estimator_\n",
    "print(f\"Best LGB params: {lgb_grid.best_params_}\")\n",
    "print(f\"Best LGB CV score: ${-lgb_grid.best_score_:,.2f}\")\n",
    "\n",
    "result_lgb = evaluate_model(best_lgb, X_train_scaled, X_test_scaled, y_train, y_test, 'LightGBM (Tuned)')\n",
    "\n",
    "tuned_results.append(result_lgb)\n",
    "tuned_models['LightGBM (Tuned)'] = best_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f623782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune CatBoost with early stopping\n",
    "cat_params = {\n",
    "    'iterations': [300, 500],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'depth': [6, 8],\n",
    "    'l2_leaf_reg': [1, 3]\n",
    "}\n",
    "\n",
    "cat_grid = RandomizedSearchCV(\n",
    "    CatBoostRegressor(random_state=42, verbose=0, thread_count=2, early_stopping_rounds=20),\n",
    "    cat_params,\n",
    "    n_iter=10,\n",
    "    cv=2,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "cat_grid.fit(X_train_scaled, y_train,\n",
    "             eval_set=(X_val_xgb, y_val_xgb),\n",
    "             verbose=False)\n",
    "\n",
    "best_params = cat_grid.best_params_.copy()\n",
    "best_cat = CatBoostRegressor(random_state=42, verbose=0, thread_count=2, **best_params)\n",
    "\n",
    "print(f\"Best CatBoost params: {cat_grid.best_params_}\")\n",
    "print(f\"Best CatBoost CV score: ${-cat_grid.best_score_:,.2f}\")\n",
    "\n",
    "result_cat = evaluate_model(best_cat, X_train_scaled, X_test_scaled, y_train, y_test, 'CatBoost (Tuned)')\n",
    "\n",
    "tuned_results.append(result_cat)\n",
    "tuned_models['CatBoost (Tuned)'] = best_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9cd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train R²</th>\n",
       "      <th>Test R²</th>\n",
       "      <th>CV RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM (Tuned)</td>\n",
       "      <td>25593.8700</td>\n",
       "      <td>43675.3600</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>44703.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost (Tuned)</td>\n",
       "      <td>26322.7000</td>\n",
       "      <td>43825.6400</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>44591.9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost (Tuned)</td>\n",
       "      <td>22454.0300</td>\n",
       "      <td>44426.8400</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>45035.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest (Tuned)</td>\n",
       "      <td>17871.8600</td>\n",
       "      <td>48587.1000</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>49280.7600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Train RMSE  Test RMSE  Train R²  Test R²    CV RMSE\n",
       "2       LightGBM (Tuned)  25593.8700 43675.3600    0.9500   0.8500 44703.1200\n",
       "3       CatBoost (Tuned)  26322.7000 43825.6400    0.9500   0.8500 44591.9200\n",
       "1        XGBoost (Tuned)  22454.0300 44426.8400    0.9600   0.8500 45035.6000\n",
       "0  Random Forest (Tuned)  17871.8600 48587.1000    0.9800   0.8200 49280.7600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_df = pd.DataFrame(tuned_results)\n",
    "tuned_df = tuned_df.sort_values('Test RMSE')\n",
    "\n",
    "display(tuned_df[['Model', 'Train RMSE', 'Test RMSE', 'Train R²', 'Test R²', 'CV RMSE']].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Ensemble - Test RMSE: $43,971.73 | Test R²: 0.8524\n"
     ]
    }
   ],
   "source": [
    "# Simple Voting Ensemble (top 4 models)\n",
    "base_estimators = [\n",
    "    ('rf', best_rf),\n",
    "    ('xgb', best_xgb),\n",
    "    ('lgb', best_lgb),\n",
    "    ('cat', best_cat)\n",
    "]\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=base_estimators, n_jobs=-1)\n",
    "voting_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "result_voting = evaluate_model(voting_reg, X_train_scaled, X_test_scaled, y_train, y_test, 'Voting Ensemble')\n",
    "print(f\"Voting Ensemble - Test RMSE: ${result_voting['Test RMSE']:,.2f} | Test R²: {result_voting['Test R²']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af41c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top 4 models for stacking\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m stacking_reg = StackingRegressor(\n\u001b[32m     11\u001b[39m     estimators=base_estimators,\n\u001b[32m     12\u001b[39m     final_estimator=Ridge(alpha=\u001b[32m5.0\u001b[39m),\n\u001b[32m     13\u001b[39m     cv=\u001b[32m2\u001b[39m,\n\u001b[32m     14\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m stacking_reg.fit(X_train_scaled, y_train)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m result_stacking = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacking_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mStacking Ensemble\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStacking - Test RMSE: $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult_stacking[\u001b[33m'\u001b[39m\u001b[33mTest RMSE\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Test R²: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult_stacking[\u001b[33m'\u001b[39m\u001b[33mTest R²\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, X_train, X_test, y_train, y_test, model_name)\u001b[39m\n\u001b[32m     13\u001b[39m test_r2 = r2_score(y_test, y_test_pred)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Cross-validation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m cv_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneg_root_mean_squared_error\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m cv_rmse = -cv_scores.mean()\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     21\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m: model_name,\n\u001b[32m     22\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTrain RMSE\u001b[39m\u001b[33m'\u001b[39m: train_rmse,\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mModel Object\u001b[39m\u001b[33m'\u001b[39m: model\n\u001b[32m     30\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CRIZMA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CRIZMA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_stacking.py:1043\u001b[39m, in \u001b[36mStackingRegressor.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m   1039\u001b[39m _raise_for_params(fit_params, \u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, allow=[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1041\u001b[39m y = column_or_1d(y, warn=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_stacking.py:253\u001b[39m, in \u001b[36m_BaseStacking.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cv, \u001b[33m\"\u001b[39m\u001b[33mrandom_state\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m cv.random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    251\u001b[39m         cv.random_state = np.random.RandomState()\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     predictions = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstack_method_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;28mself\u001b[39m.stack_method_ = [\n\u001b[32m    271\u001b[39m     meth\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.stack_method_, all_estimators)\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m est != \u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    274\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CRIZMA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CRIZMA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CRIZMA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "top_4_models = tuned_df.head(4)['Model'].tolist()\n",
    "base_estimators = []\n",
    "for model_name in top_4_models:\n",
    "    model_obj = tuned_df[tuned_df['Model'] == model_name]['Model Object'].values[0]\n",
    "    base_estimators.append((model_name.replace(' ', '_').replace('(', '').replace(')', ''), model_obj))\n",
    "\n",
    "print(f\"Using top {len(base_estimators)} models for stacking\")\n",
    "\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=Ridge(alpha=5.0),\n",
    "    cv=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_reg.fit(X_train_scaled, y_train)\n",
    "result_stacking = evaluate_model(stacking_reg, X_train_scaled, X_test_scaled, y_train, y_test, 'Stacking Ensemble')\n",
    "print(f\"Stacking - Test RMSE: ${result_stacking['Test RMSE']:,.2f} | Test R²: {result_stacking['Test R²']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Ensemble\n",
    "weights = []\n",
    "for model_name in top_4_models:\n",
    "    rmse = tuned_df[tuned_df['Model'] == model_name]['Test RMSE'].values[0]\n",
    "    weights.append(1 / (rmse ** 2))\n",
    "\n",
    "weights = np.array(weights)\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "print(\"Model Weights:\")\n",
    "for name, weight in zip(top_4_models, weights):\n",
    "    print(f\"  {name}: {weight:.4f}\")\n",
    "\n",
    "weighted_voting = VotingRegressor(estimators=base_estimators, weights=weights, n_jobs=-1)\n",
    "weighted_voting.fit(X_train_scaled, y_train)\n",
    "\n",
    "result_weighted = evaluate_model(weighted_voting, X_train_scaled, X_test_scaled, y_train, y_test, 'Weighted Voting')\n",
    "print(f\"Weighted Voting - Test RMSE: ${result_weighted['Test RMSE']:,.2f} | Test R²: {result_weighted['Test R²']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e78e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_results = [result_voting, result_stacking, result_weighted]\n",
    "all_results = results + tuned_results + ensemble_results\n",
    "\n",
    "final_df = pd.DataFrame(all_results)\n",
    "final_df = final_df.sort_values('Test RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL MODEL PERFORMANCE RANKING\")\n",
    "print(\"=\"*80)\n",
    "display(final_df[['Model', 'Train RMSE', 'Test RMSE', 'Train R²', 'Test R²', 'CV RMSE']].round(2).head(10))\n",
    "\n",
    "print(f\"\\nBEST MODEL: {final_df.iloc[0]['Model']}\")\n",
    "print(f\"   Test RMSE: ${final_df.iloc[0]['Test RMSE']:,.2f}\")\n",
    "print(f\"   Test R²: {final_df.iloc[0]['Test R²']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4600b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "top_10 = final_df.head(10)\n",
    "ax.barh(top_10['Model'], top_10['Test RMSE'], color='steelblue', alpha=0.8)\n",
    "ax.set_xlabel('Test RMSE ($)')\n",
    "ax.set_title('Top 10 Models - Test RMSE Comparison', fontweight='bold', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs(r'D:\\AI\\ai2-project\\models', exist_ok=True)\n",
    "\n",
    "best_model_name = final_df.iloc[0]['Model']\n",
    "best_model_obj = final_df.iloc[0]['Model Object']\n",
    "\n",
    "model_path = r'D:\\AI\\ai2-project\\models\\best_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(best_model_obj, f)\n",
    "\n",
    "scaler_path = r'D:\\AI\\ai2-project\\models\\scaler.pkl'\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "selector_path = r'D:\\AI\\ai2-project\\models\\selector.pkl'\n",
    "with open(selector_path, 'wb') as f:\n",
    "    pickle.dump(selector, f)\n",
    "\n",
    "poly_path = r'D:\\AI\\ai2-project\\models\\poly_features.pkl'\n",
    "with open(poly_path, 'wb') as f:\n",
    "    pickle.dump(poly, f)\n",
    "\n",
    "metadata = {\n",
    "    'model_name': best_model_name,\n",
    "    'test_rmse': final_df.iloc[0]['Test RMSE'],\n",
    "    'test_r2': final_df.iloc[0]['Test R²'],\n",
    "    'selected_features': selected_features\n",
    "}\n",
    "\n",
    "metadata_path = r'D:\\AI\\ai2-project\\models\\model_metadata.pkl'\n",
    "with open(metadata_path, 'wb') as f:\n",
    "    pickle.dump(metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
